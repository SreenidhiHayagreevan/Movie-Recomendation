{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EytVKX4asRqv",
        "outputId": "3e962f4a-ec3a-42ba-c959-c043069725a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_YLlEwEsRtj",
        "outputId": "e236c0ba-19c1-4c5a-e5d3-77cc2ebdef59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas nltk scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "111e5fab51d4436fb086fe1a22592a6d",
            "dc4cabf4767848feb3bf3bc6c604c003",
            "68245612e87747bfba3bb04a40ed2fa2",
            "dc7eb433c22c4d0faf1a4720ded66ea0",
            "2ad845f73097439c97c93972e1873ebc",
            "7572d489433b482b9190f44edf26caa4",
            "b12ae2543c1344cd8ac3eeef22be443b",
            "336da3f20b4b4a9fb210f785da66e9f3",
            "58c55a3be4414da1bb2041f49c005ed3",
            "03a6d7c2ad6f4259a5221bbf9a16ac63",
            "8f189425d1fd49838895ffc48da8276c"
          ]
        },
        "id": "2cE5UenhsTBH",
        "outputId": "bee32d1a-cebe-4e86-d4cc-1705fc1d2531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK 'punkt' resource found.\n",
            "NLTK 'stopwords' resource found.\n",
            "Reading CSV file: movies_subtitles.csv...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-2206bcd280eb>:315: ParserWarning: Skipping line 6942462: unexpected end of data\n",
            "\n",
            "  df = pd.read_csv(input_path, on_bad_lines='warn', engine='python') # Try python engine for flexibility\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial rows loaded: 6942460\n",
            "Rows after dropping NA in key columns: 6936991\n",
            "Combining subtitles for each 'imdb_id'...\n",
            "Found 3124 unique movies.\n",
            "Analyzing subtitles (this may take a while)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "111e5fab51d4436fb086fe1a22592a6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Analyzing Movies:   0%|          | 0/3124 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "\n",
            "--- NLTK Tokenizer Warning ---\n",
            "Sentence tokenization failed for an entry due to missing NLTK resource: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "This might happen if the 'punkt' download is incomplete or corrupted.\n",
            "Skipping summary generation for this entry.\n",
            "Consider running 'nltk.download(\"punkt\", force=True)' or 'nltk.download(\"all\")' manually.\n",
            "----------------------------\n",
            "\n",
            "An unexpected error occurred during genre identification: \n",
            "**********************************************************************\n",
            "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('punkt_tab')\n",
            "  \u001b[0m\n",
            "  For more information see: https://www.nltk.org/data.html\n",
            "\n",
            "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
            "\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "Analysis complete.\n",
            "Results saved to: movie_analysis_output.csv\n",
            "\n",
            "--- Sample Output (First 5 rows) ---\n",
            "     imdb_id  \\\n",
            "0  tt0005059   \n",
            "1  tt0008133   \n",
            "2  tt0011237   \n",
            "3  tt0012675   \n",
            "4  tt0013442   \n",
            "\n",
            "                                                                                              overview  \\\n",
            "0  <i>And all I have to do today</i> <i>Is get past remembering...</i> Maybe. Just this once. Let m...   \n",
            "1  In expectation of what you're\\ngoing through in a few moments you will be directed upstairs to c...   \n",
            "2  No contemporary version of \"The Golem,\\nhow he came into the world\" has survived. From the expos...   \n",
            "3  THE SHEIK In this world of\\npeace and flame Lies a palm garden\\nof the Sahara A blessed oasis\\no...   \n",
            "4  NOSFERATU.\\nA SYMPHONY OF HORROR. After the novel Dracula\\nby Bram Stoker. Freely adapted by\\nHe...   \n",
            "\n",
            "                                                                        keywords  \\\n",
            "0                     okay, just, im, yeah, like, know, dont, cass, right, thats   \n",
            "1                     dont, im, come, know, yes, bruno, money, ewa, right, thank   \n",
            "2  golem, rabbi, word, chapter, people, rabbi lw, lw, emperor, astaroth, revered   \n",
            "3           desert, ahmed, love, biskra, allah, omair, make, hands, diana, sheik   \n",
            "4             nosferatu, blood, like, hutter, act, end, doth, plague, ill, death   \n",
            "\n",
            "    genres  \n",
            "0  Unknown  \n",
            "1  Unknown  \n",
            "2  Unknown  \n",
            "3  Unknown  \n",
            "4  Unknown  \n",
            "\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Add encoding declaration for potentially non-ascii characters in comments/code\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "import heapq # For efficient summarization sentence selection\n",
        "import sys # To potentially exit if downloads fail\n",
        "\n",
        "# --- Configuration ---\n",
        "INPUT_CSV_FILE = 'movies_subtitles.csv'  # <--- CHANGE THIS if needed\n",
        "OUTPUT_CSV_FILE = 'movie_analysis_output.csv' # <--- CHANGE THIS (Optional output file)\n",
        "MOVIE_ID_COLUMN = 'imdb_id'          # <--- CHANGE THIS if your column name is different\n",
        "SUBTITLE_TEXT_COLUMN = 'text' # <--- CHANGE THIS if your column name is different\n",
        "\n",
        "MAX_OVERVIEW_CHARS = 1000\n",
        "NUM_KEYWORDS = 10\n",
        "\n",
        "# --- Download necessary NLTK data (if not already downloaded) ---\n",
        "# Use correct exception handling (LookupError)\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "    print(\"NLTK 'punkt' resource found.\")\n",
        "except LookupError:\n",
        "    print(\"Downloading NLTK 'punkt' tokenizer...\")\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    try:\n",
        "        nltk.data.find('tokenizers/punkt')\n",
        "        print(\"'punkt' downloaded successfully.\")\n",
        "    except LookupError:\n",
        "        print(\"\\n--- !!! ERROR !!! ---\")\n",
        "        print(\"Failed to download or locate the NLTK 'punkt' resource even after download attempt.\")\n",
        "        print(\"Please check your internet connection and NLTK setup.\")\n",
        "        print(\"You might need to manually download NLTK data (e.g., nltk.download('all')).\")\n",
        "        print(\"See: https://www.nltk.org/data.html\")\n",
        "        print(\"Exiting script.\")\n",
        "        print(\"---------------------\\n\")\n",
        "        sys.exit(\"Required NLTK resource 'punkt' missing.\")\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "    print(\"NLTK 'stopwords' resource found.\")\n",
        "except LookupError:\n",
        "    print(\"Downloading NLTK 'stopwords'...\")\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    try:\n",
        "        nltk.data.find('corpora/stopwords')\n",
        "        print(\"'stopwords' downloaded successfully.\")\n",
        "    except LookupError:\n",
        "        print(\"\\n--- !!! ERROR !!! ---\")\n",
        "        print(\"Failed to download or locate the NLTK 'stopwords' resource.\")\n",
        "        print(\"Exiting script.\")\n",
        "        print(\"---------------------\\n\")\n",
        "        sys.exit(\"Required NLTK resource 'stopwords' missing.\")\n",
        "\n",
        "# Define STOP_WORDS *after* ensuring NLTK data is available\n",
        "try:\n",
        "    STOP_WORDS = set(stopwords.words('english'))\n",
        "except Exception as e:\n",
        "     print(f\"\\n--- !!! ERROR !!! ---\")\n",
        "     print(f\"Failed to load NLTK stopwords. Error: {e}\")\n",
        "     print(\"Proceeding without stopwords, keyword quality may be affected.\")\n",
        "     print(\"---------------------\\n\")\n",
        "     STOP_WORDS = set() # Use empty set if loading fails\n",
        "\n",
        "# --- Genre Keywords (Heuristic - Expand as needed) ---\n",
        "GENRE_KEYWORDS = {\n",
        "    'Action': ['fight', 'gun', 'chase', 'explosion', 'kill', 'attack', 'shoot', 'run', 'escape', 'mission', 'weapon', 'battle', 'war'],\n",
        "    'Comedy': ['funny', 'laugh', 'joke', 'haha', 'stupid', 'crazy', 'hilarious', 'idiot', 'comedian', 'fun', 'silly'],\n",
        "    'Drama': ['sad', 'cry', 'feelings', 'sorry', 'relationship', 'family', 'life', 'death', 'serious', 'story', 'love', 'lost', 'hope'],\n",
        "    'Sci-Fi': ['space', 'alien', 'robot', 'future', 'planet', 'ship', 'laser', 'time travel', 'science', 'galaxy', 'android', 'tech', 'technology', 'ai'],\n",
        "    'Horror': ['scared', 'fear', 'ghost', 'monster', 'scream', 'blood', 'die', 'haunted', 'terror', 'nightmare', 'killer', 'dark', 'evil'],\n",
        "    'Romance': ['love', 'kiss', 'heart', 'date', 'beautiful', 'together', 'forever', 'darling', 'marry', 'sweet', 'couple', 'wedding'],\n",
        "    'Thriller': ['suspense', 'danger', 'nervous', 'plot', 'secret', 'mystery', 'trap', 'risk', 'threat', 'tense', 'escape', 'spy', 'agent'],\n",
        "    'Fantasy': ['magic', 'wizard', 'dragon', 'sword', 'kingdom', 'elf', 'quest', 'myth', 'legend', 'creature', 'king', 'queen', 'prince', 'princess'],\n",
        "    'Animation': [], # Still hard from text alone\n",
        "    'Documentary': ['real', 'story', 'life', 'world', 'people', 'history', 'fact', 'interview', 'evidence', 'nature', 'science'] # Also difficult\n",
        "}\n",
        "# Add more genres and keywords for better accuracy\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Basic text cleaning: lowercase, remove artifacts, non-alphanumeric.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    # Remove timestamps like 00:00:15,203 --> 00:00:18,163\n",
        "    text = re.sub(r'\\d{1,2}:\\d{2}:\\d{2},\\d{3}\\s*-->\\s*\\d{1,2}:\\d{2}:\\d{2},\\d{3}', '', text)\n",
        "    # Remove simple timestamps like [00:15] or {00:15}\n",
        "    text = re.sub(r'[\\[\\{\\(]\\s*\\d{1,2}:\\d{2}(:\\d{2})?\\s*[\\]\\}\\)]', '', text) # Handle optional seconds\n",
        "    # Remove typical subtitle formatting like <i>, <b>, font tags etc.\n",
        "    text = re.sub(r'<[/ BUI]?.*?>', '', text, flags=re.IGNORECASE) # More generic tag removal\n",
        "    # Remove speaker tags like [MAN], (WOMAN), MAN:, etc. (more robust)\n",
        "    text = re.sub(r'^[\\s\\t]*[A-Z\\s]+:', '', text, flags=re.MULTILINE) # Speaker at line start\n",
        "    text = re.sub(r'[\\[\\{\\(][^\\]\\}\\)]*?:.*?[\\]\\}\\)]', '', text) # Speaker tag like [MAN]: or (WOMAN SIGHING):\n",
        "    # Remove music notes or symbols if present\n",
        "    text = re.sub(r'[#*]', '', text)\n",
        "    # Remove sequences indicating OCR errors or breaks like '---' or '==='\n",
        "    text = re.sub(r'[-=]{2,}', ' ', text)\n",
        "    # General cleaning: remove remaining non-alphanumeric, non-space chars\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def generate_overview_extractive(full_text, max_chars=MAX_OVERVIEW_CHARS):\n",
        "    \"\"\"Generates an extractive summary using sentence scoring based on word frequency.\"\"\"\n",
        "    if not full_text or not isinstance(full_text, str) or len(full_text.strip()) < 10:\n",
        "        return \"\"\n",
        "\n",
        "    # *** ADDED try-except specifically for sent_tokenize ***\n",
        "    try:\n",
        "        sentences = sent_tokenize(full_text)\n",
        "    except LookupError as e:\n",
        "        # This catches the persistent 'punkt_tab not found' or similar NLTK data issues\n",
        "        print(f\"\\n--- NLTK Tokenizer Warning ---\")\n",
        "        print(f\"Sentence tokenization failed for an entry due to missing NLTK resource: {e}\")\n",
        "        print(\"This might happen if the 'punkt' download is incomplete or corrupted.\")\n",
        "        print(\"Skipping summary generation for this entry.\")\n",
        "        print(\"Consider running 'nltk.download(\\\"punkt\\\", force=True)' or 'nltk.download(\\\"all\\\")' manually.\")\n",
        "        print(\"----------------------------\\n\")\n",
        "        # Fallback: return the beginning of the raw text\n",
        "        return full_text[:max_chars].strip()\n",
        "    except Exception as e:\n",
        "        # Catch other potential tokenization errors\n",
        "        print(f\"Warning: Sentence tokenization failed unexpectedly. Error: {e}. Skipping summary.\")\n",
        "        return full_text[:max_chars].strip() # Fallback\n",
        "\n",
        "    if not sentences:\n",
        "        return \"\"\n",
        "\n",
        "    cleaned_full_text = preprocess_text(full_text)\n",
        "    if not cleaned_full_text:\n",
        "        return sentences[0][:max_chars] if sentences else \"\" # Fallback if cleaning removes everything\n",
        "\n",
        "    words = word_tokenize(cleaned_full_text)\n",
        "    word_frequencies = Counter(word for word in words if word not in STOP_WORDS and len(word) > 1)\n",
        "\n",
        "    if not word_frequencies:\n",
        "         return sentences[0][:max_chars] if sentences else \"\" # Return beginning if no significant words\n",
        "\n",
        "    sentence_scores = {}\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        cleaned_sentence_words = word_tokenize(preprocess_text(sentence))\n",
        "        score = sum(word_frequencies[word] for word in cleaned_sentence_words if word in word_frequencies)\n",
        "        sentence_scores[i] = score\n",
        "\n",
        "    num_sentences_to_consider = min(len(sentences) // 2 + 1, 20)\n",
        "    k = min(num_sentences_to_consider, len(sentences))\n",
        "    if k <= 0: return \"\"\n",
        "\n",
        "    try:\n",
        "        # Ensure sentence_scores is not empty before using heapq\n",
        "        if not sentence_scores:\n",
        "             top_sentence_indices = list(range(min(k, len(sentences)))) # Take first k sentences if no scores\n",
        "        else:\n",
        "            top_sentence_indices = heapq.nlargest(k, sentence_scores, key=sentence_scores.get)\n",
        "            top_sentence_indices.sort()\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Error during sentence selection for summary: {e}. Using first sentences.\")\n",
        "        top_sentence_indices = list(range(min(k, len(sentences)))) # Fallback\n",
        "\n",
        "\n",
        "    summary = \"\"\n",
        "    current_length = 0\n",
        "    for index in top_sentence_indices:\n",
        "        if index < len(sentences):\n",
        "            sentence = sentences[index].strip()\n",
        "            if not sentence: continue # Skip empty sentences\n",
        "\n",
        "            needed_length = len(sentence) + (1 if summary else 0) # +1 for space\n",
        "            if current_length + needed_length <= max_chars:\n",
        "                summary += (\" \" if summary else \"\") + sentence\n",
        "                current_length += needed_length\n",
        "            else:\n",
        "                if not summary: # If first sentence is too long, truncate it\n",
        "                    summary = sentence[:max_chars]\n",
        "                    current_length = len(summary)\n",
        "                break # Stop adding sentences\n",
        "\n",
        "    if not summary and sentences:\n",
        "         summary = sentences[0][:max_chars].strip()\n",
        "\n",
        "    return summary.strip()[:max_chars]\n",
        "\n",
        "\n",
        "def extract_keywords_tfidf(full_text, num_keywords=NUM_KEYWORDS):\n",
        "    \"\"\"Extracts keywords using TF-IDF.\"\"\"\n",
        "    keywords = [] # Initialize keywords list\n",
        "    try:\n",
        "        if not full_text or not isinstance(full_text, str):\n",
        "            return []\n",
        "\n",
        "        processed_text = preprocess_text(full_text)\n",
        "        if not processed_text or len(processed_text.split()) < 5: # Need at least a few words\n",
        "             # Fallback: simple frequency if text too short\n",
        "             words = word_tokenize(processed_text)\n",
        "             word_counts = Counter(w for w in words if w not in STOP_WORDS and len(w) > 2)\n",
        "             keywords = [word for word, count in word_counts.most_common(num_keywords)]\n",
        "             return keywords\n",
        "\n",
        "        # *** FIXED: Set min_df=1 for single-document processing ***\n",
        "        vectorizer = TfidfVectorizer(stop_words='english',\n",
        "                                     ngram_range=(1, 2),\n",
        "                                     max_features=2000,\n",
        "                                     min_df=1) # Must be 1 when fitting on single doc\n",
        "        tfidf_matrix = vectorizer.fit_transform([processed_text])\n",
        "\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "        scores = tfidf_matrix.toarray().flatten()\n",
        "\n",
        "        if len(feature_names) == 0:\n",
        "             words = word_tokenize(processed_text)\n",
        "             word_counts = Counter(w for w in words if w not in STOP_WORDS and len(w) > 2)\n",
        "             keywords = [word for word, count in word_counts.most_common(num_keywords)]\n",
        "             return keywords\n",
        "\n",
        "        actual_num_keywords = min(num_keywords, len(feature_names))\n",
        "        top_indices = scores.argsort()[-actual_num_keywords:][::-1]\n",
        "\n",
        "        keywords = [feature_names[i] for i in top_indices]\n",
        "        return keywords\n",
        "\n",
        "    except ValueError as e:\n",
        "        # Catch specific TF-IDF errors or others\n",
        "        print(f\"Warning: TF-IDF keyword extraction failed. Error: {e}. Falling back to word count.\")\n",
        "        # Fallback: simple frequency (ensure processed_text is defined)\n",
        "        if 'processed_text' not in locals(): # If error happened before processed_text was assigned\n",
        "             processed_text = preprocess_text(full_text) if isinstance(full_text, str) else \"\"\n",
        "        words = word_tokenize(processed_text)\n",
        "        word_counts = Counter(w for w in words if w not in STOP_WORDS and len(w) > 2)\n",
        "        keywords = [word for word, count in word_counts.most_common(num_keywords)]\n",
        "        return keywords\n",
        "    except Exception as e:\n",
        "         print(f\"An unexpected error occurred during keyword extraction: {e}\")\n",
        "         return [] # Return empty list on unexpected error\n",
        "\n",
        "\n",
        "def identify_genres_heuristic(full_text, threshold_multiplier=0.0005, min_keyword_matches=3):\n",
        "    \"\"\"Identifies potential genres based on keyword frequency and relative importance.\"\"\"\n",
        "    try:\n",
        "        if not full_text or not isinstance(full_text, str):\n",
        "            return [\"Unknown\"]\n",
        "\n",
        "        processed_text = preprocess_text(full_text)\n",
        "        if not processed_text:\n",
        "            return [\"Unknown\"]\n",
        "\n",
        "        words = word_tokenize(processed_text)\n",
        "        total_words = len(words)\n",
        "        if total_words == 0:\n",
        "            return [\"Unknown\"]\n",
        "\n",
        "        word_counts = Counter(words)\n",
        "\n",
        "        genre_scores = {}\n",
        "        for genre, keywords in GENRE_KEYWORDS.items():\n",
        "            if not keywords: continue\n",
        "            score = 0\n",
        "            matches = 0\n",
        "            for keyword in keywords:\n",
        "                if ' ' in keyword:\n",
        "                    phrase_count = processed_text.count(keyword)\n",
        "                    if phrase_count > 0:\n",
        "                        score += phrase_count * 2\n",
        "                        matches += phrase_count\n",
        "                elif keyword in word_counts:\n",
        "                    count = word_counts[keyword]\n",
        "                    score += count\n",
        "                    matches += count\n",
        "\n",
        "            normalized_score = score / total_words if total_words > 0 else 0\n",
        "            # Adjust threshold logic slightly: consider if score > 0 at all if few matches\n",
        "            passes_threshold = (matches >= min_keyword_matches and normalized_score > (len(keywords) * threshold_multiplier)) or \\\n",
        "                               (matches > 0 and matches < min_keyword_matches and normalized_score > 0) # Allow genres with few but present keywords\n",
        "\n",
        "            if passes_threshold:\n",
        "                 genre_scores[genre] = normalized_score\n",
        "\n",
        "        if not genre_scores:\n",
        "            return [\"Unknown\"]\n",
        "\n",
        "        sorted_genres = sorted(genre_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "        num_genres_to_return = 0\n",
        "        if len(sorted_genres) >= 3 and sorted_genres[1][1] > sorted_genres[0][1] * 0.4:\n",
        "            num_genres_to_return = 3\n",
        "        elif len(sorted_genres) >= 2 and sorted_genres[1][1] > sorted_genres[0][1] * 0.5:\n",
        "            num_genres_to_return = 2\n",
        "        elif len(sorted_genres) >= 1:\n",
        "            num_genres_to_return = 1\n",
        "        else:\n",
        "            return [\"Unknown\"]\n",
        "\n",
        "        num_genres_to_return = min(num_genres_to_return, len(sorted_genres))\n",
        "        matched_genres = [genre for genre, score in sorted_genres[:num_genres_to_return]]\n",
        "\n",
        "        return matched_genres if matched_genres else [\"Unknown\"]\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during genre identification: {e}\")\n",
        "        return [\"Unknown\"]\n",
        "\n",
        "\n",
        "# --- Main Processing Function ---\n",
        "\n",
        "def process_subtitle_file(input_path, output_path, id_col, text_col):\n",
        "    \"\"\"Reads, processes, and analyzes the subtitle CSV.\"\"\"\n",
        "    print(f\"Reading CSV file: {input_path}...\")\n",
        "    try:\n",
        "        df = pd.read_csv(input_path, on_bad_lines='warn', engine='python') # Try python engine for flexibility\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file not found at {input_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CSV: {e}\")\n",
        "        # If reading fails entirely, maybe try different encoding?\n",
        "        try:\n",
        "            print(\"Attempting to read CSV with latin-1 encoding...\")\n",
        "            df = pd.read_csv(input_path, on_bad_lines='warn', encoding='latin-1', engine='python')\n",
        "        except Exception as e2:\n",
        "            print(f\"Error reading CSV with latin-1 encoding as well: {e2}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "    if id_col not in df.columns or text_col not in df.columns:\n",
        "        print(f\"Error: Missing required columns '{id_col}' or '{text_col}' in the CSV.\")\n",
        "        print(f\"Available columns: {df.columns.tolist()}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Initial rows loaded: {len(df)}\")\n",
        "    df.dropna(subset=[id_col, text_col], inplace=True)\n",
        "    print(f\"Rows after dropping NA in key columns: {len(df)}\")\n",
        "\n",
        "    df[text_col] = df[text_col].apply(lambda x: str(x) if pd.notnull(x) else '')\n",
        "\n",
        "    print(f\"Combining subtitles for each '{id_col}'...\")\n",
        "    try:\n",
        "        # Use aggregation which might be more memory efficient for large groups\n",
        "        combined_df = df.groupby(id_col)[text_col].agg(' '.join).reset_index()\n",
        "        combined_df.rename(columns={text_col: 'full_subtitles'}, inplace=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during grouping and combining subtitles: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Found {len(combined_df)} unique movies.\")\n",
        "    if len(combined_df) == 0:\n",
        "        print(\"No movie data found after grouping. Check your ID column and data.\")\n",
        "        return None\n",
        "\n",
        "    print(\"Analyzing subtitles (this may take a while)...\")\n",
        "\n",
        "    results = []\n",
        "    try:\n",
        "        from tqdm.auto import tqdm\n",
        "        iterator = tqdm(combined_df.iterrows(), total=len(combined_df), desc=\"Analyzing Movies\")\n",
        "    except ImportError:\n",
        "        print(\"Optional dependency 'tqdm' not found. Progress bar disabled. Install with: pip install tqdm\")\n",
        "        iterator = combined_df.iterrows()\n",
        "        progress_interval = max(1, len(combined_df) // 20)\n",
        "        processed_count = 0\n",
        "\n",
        "    for index, row in iterator:\n",
        "        movie_id = row[id_col]\n",
        "        full_text = row['full_subtitles']\n",
        "\n",
        "        # --- Analysis ---\n",
        "        # Wrap analysis steps in a try-except block for robustness per movie\n",
        "        try:\n",
        "             overview = generate_overview_extractive(full_text, MAX_OVERVIEW_CHARS)\n",
        "             keywords = extract_keywords_tfidf(full_text, NUM_KEYWORDS)\n",
        "             genres = identify_genres_heuristic(full_text)\n",
        "        except Exception as e:\n",
        "             print(f\"\\n--- ERROR processing movie ID: {movie_id} ---\")\n",
        "             print(f\"An unexpected error occurred: {e}\")\n",
        "             print(\"Skipping analysis for this movie.\")\n",
        "             print(\"----------------------------------------------\\n\")\n",
        "             overview = \"Analysis Error\"\n",
        "             keywords = []\n",
        "             genres = [\"Error\"]\n",
        "\n",
        "\n",
        "        results.append({\n",
        "            MOVIE_ID_COLUMN: movie_id,\n",
        "            'overview': overview,\n",
        "            'keywords': ', '.join(keywords),\n",
        "            'genres': ', '.join(genres),\n",
        "        })\n",
        "\n",
        "        if 'tqdm' not in sys.modules:\n",
        "            processed_count += 1\n",
        "            if processed_count % progress_interval == 0 or processed_count == len(combined_df):\n",
        "                 print(f\"  Processed {processed_count}/{len(combined_df)} movies...\")\n",
        "\n",
        "    print(\"Analysis complete.\")\n",
        "\n",
        "    if not results:\n",
        "        print(\"Warning: No results were generated from the analysis.\")\n",
        "        return None\n",
        "\n",
        "    output_df = pd.DataFrame(results)\n",
        "\n",
        "    try:\n",
        "        output_df.to_csv(output_path, index=False, encoding='utf-8')\n",
        "        print(f\"Results saved to: {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving results to CSV: {e}\")\n",
        "\n",
        "    return output_df\n",
        "\n",
        "# --- Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    processed_data = process_subtitle_file(\n",
        "        INPUT_CSV_FILE,\n",
        "        OUTPUT_CSV_FILE,\n",
        "        MOVIE_ID_COLUMN,\n",
        "        SUBTITLE_TEXT_COLUMN\n",
        "    )\n",
        "\n",
        "    if processed_data is not None:\n",
        "        print(\"\\n--- Sample Output (First 5 rows) ---\")\n",
        "        # Display more content if overview/keywords are long\n",
        "        with pd.option_context('display.max_colwidth', 100):\n",
        "             print(processed_data.head())\n",
        "        print(\"\\n-------------------------------------\")\n",
        "    else:\n",
        "        print(\"Processing failed or produced no results.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 248,
          "referenced_widgets": [
            "8bbd6065a1ac4d43a1a11e2d3856a4e9",
            "4cb0d0cbeb0747349a92b765c55dd3ac",
            "2ce8724a0a0545178d53a2105f3dcb99",
            "c4f6861260fd4fceba61f0c6d45a433f",
            "988f2f840b9c4b9883e2a98a949518ec",
            "c748f7f0ebf34699b824cd65646579b4",
            "c4130824a7254f4b9a45d6cd2c93a3d4",
            "1141c1dd9fe84a6babcf11a6792ae3b6",
            "7000e58e578e4ad8ae5f3782e6f13ace",
            "bbabb58bd65446a4a204820b842b06cf",
            "0ee0a143677c4005ac937e10b0cb01a5"
          ]
        },
        "id": "ycsuJZN_SPmC",
        "outputId": "55fb3442-f5df-4823-aa66-69b99738b2ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK 'punkt' resource found.\n",
            "NLTK 'stopwords' resource found.\n",
            "NLTK 'punkt_tab' resource found.\n",
            "Reading CSV file: movies_subtitles.csv...\n",
            "Initial rows loaded: 10358496\n",
            "Rows after dropping NA in key columns: 10346661\n",
            "Combining subtitles for each 'imdb_id'...\n",
            "Found 4665 unique movies.\n",
            "Analyzing subtitles (this may take a while)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bbd6065a1ac4d43a1a11e2d3856a4e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Analyzing Movies:   0%|          | 0/4665 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analysis complete.\n",
            "Results saved to: movie_analysis_output.csv\n",
            "\n",
            "--- Sample Output (First 5 rows) ---\n",
            "     imdb_id  \\\n",
            "0  tt0002130   \n",
            "1  tt0005044   \n",
            "2  tt0005059   \n",
            "3  tt0005060   \n",
            "4  tt0007338   \n",
            "\n",
            "                                                                                              overview  \\\n",
            "0  I'll never get to sleep. Hold the line... <i>Well,</i> <i>you know what to expect now.</i> She d...   \n",
            "1  Don't pretend you don't know\\nwhat I'm talking about. I don't know what the\\nfuck you're talking...   \n",
            "2  Whether you got a white skate on one\\nfoot and a black on the other it's... What's the... what's...   \n",
            "3  nd then we'll follow you,\\ndark-haired cigarette girls, and whisper words of love\\nin every ear...   \n",
            "4  Well with all due respect, Mr. Holmes,\\nYou know John very well. - I don't think that's... - I d...   \n",
            "\n",
            "                                                              keywords  \\\n",
            "0            im, ill, dont, youre, just, look, thats, paul, come, shes   \n",
            "1            dont, know, stop, youre, im, want, just, like, good, yeah   \n",
            "2           okay, just, im, yeah, like, know, dont, cass, right, thats   \n",
            "3              love, carmen, come, nd, ill, im, dont, yes, wont, youll   \n",
            "4  holmes, sir, youre, dont, blackwood, right, thats, know, im, watson   \n",
            "\n",
            "                    genres  \n",
            "0                    Drama  \n",
            "1          Action, Fantasy  \n",
            "2                  Unknown  \n",
            "3  Romance, Drama, Fantasy  \n",
            "4                  Unknown  \n",
            "\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Add encoding declaration for potentially non-ascii characters in comments/code\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "import heapq # For efficient summarization sentence selection\n",
        "import sys # To potentially exit if downloads fail\n",
        "\n",
        "# --- Configuration ---\n",
        "# ... (your configuration remains the same) ...\n",
        "INPUT_CSV_FILE = 'movies_subtitles.csv'\n",
        "OUTPUT_CSV_FILE = 'movie_analysis_output.csv'\n",
        "MOVIE_ID_COLUMN = 'imdb_id'\n",
        "SUBTITLE_TEXT_COLUMN = 'text'\n",
        "MAX_OVERVIEW_CHARS = 1000\n",
        "NUM_KEYWORDS = 10\n",
        "\n",
        "\n",
        "# --- Download necessary NLTK data (if not already downloaded) ---\n",
        "# Use correct exception handling (LookupError)\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "    print(\"NLTK 'punkt' resource found.\")\n",
        "except LookupError:\n",
        "    print(\"Downloading NLTK 'punkt' tokenizer...\")\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    try:\n",
        "        nltk.data.find('tokenizers/punkt')\n",
        "        print(\"'punkt' downloaded successfully.\")\n",
        "    except LookupError:\n",
        "        print(\"\\n--- !!! ERROR !!! ---\")\n",
        "        print(\"Failed to download or locate the NLTK 'punkt' resource even after download attempt.\")\n",
        "        print(\"Please check your internet connection and NLTK setup.\")\n",
        "        print(\"You might need to manually download NLTK data (e.g., nltk.download('all')).\")\n",
        "        print(\"See: https://www.nltk.org/data.html\")\n",
        "        print(\"Exiting script.\")\n",
        "        print(\"---------------------\\n\")\n",
        "        sys.exit(\"Required NLTK resource 'punkt' missing.\")\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "    print(\"NLTK 'stopwords' resource found.\")\n",
        "except LookupError:\n",
        "    print(\"Downloading NLTK 'stopwords'...\")\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    try:\n",
        "        nltk.data.find('corpora/stopwords')\n",
        "        print(\"'stopwords' downloaded successfully.\")\n",
        "    except LookupError:\n",
        "        print(\"\\n--- !!! ERROR !!! ---\")\n",
        "        print(\"Failed to download or locate the NLTK 'stopwords' resource.\")\n",
        "        print(\"Exiting script.\")\n",
        "        print(\"---------------------\\n\")\n",
        "        sys.exit(\"Required NLTK resource 'stopwords' missing.\")\n",
        "\n",
        "# *** ADDED SECTION FOR PUNKT_TAB ***\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab') # The error indicates this specific path\n",
        "    print(\"NLTK 'punkt_tab' resource found.\")\n",
        "except LookupError:\n",
        "    print(\"Downloading NLTK 'punkt_tab' resource (needed by 'punkt' tokenizer for some cases)...\")\n",
        "    nltk.download('punkt_tab', quiet=True)\n",
        "    try:\n",
        "        nltk.data.find('tokenizers/punkt_tab')\n",
        "        print(\"'punkt_tab' downloaded successfully.\")\n",
        "    except LookupError:\n",
        "        print(\"\\n--- !!! ERROR !!! ---\")\n",
        "        print(\"Failed to download or locate the NLTK 'punkt_tab' resource even after download attempt.\")\n",
        "        print(\"This resource is sometimes required by the 'punkt' tokenizer.\")\n",
        "        print(\"Please check your internet connection and NLTK setup.\")\n",
        "        print(\"If the issue persists, you might need to investigate NLTK's data directory or try 'nltk.download(\\\"all\\\")'.\")\n",
        "        print(\"Exiting script as tokenization might fail unpredictably.\")\n",
        "        print(\"---------------------\\n\")\n",
        "        sys.exit(\"Required NLTK resource 'punkt_tab' missing.\")\n",
        "# *** END OF ADDED SECTION FOR PUNKT_TAB ***\n",
        "\n",
        "\n",
        "# Define STOP_WORDS *after* ensuring NLTK data is available\n",
        "try:\n",
        "    STOP_WORDS = set(stopwords.words('english'))\n",
        "except Exception as e:\n",
        "     print(f\"\\n--- !!! ERROR !!! ---\")\n",
        "     print(f\"Failed to load NLTK stopwords. Error: {e}\")\n",
        "     print(\"Proceeding without stopwords, keyword quality may be affected.\")\n",
        "     print(\"---------------------\\n\")\n",
        "     STOP_WORDS = set() # Use empty set if loading fails\n",
        "\n",
        "# --- Genre Keywords (Heuristic - Expand as needed) ---\n",
        "# ... (your GENRE_KEYWORDS and helper functions remain the same) ...\n",
        "GENRE_KEYWORDS = {\n",
        "    'Action': ['fight', 'gun', 'chase', 'explosion', 'kill', 'attack', 'shoot', 'run', 'escape', 'mission', 'weapon', 'battle', 'war'],\n",
        "    'Comedy': ['funny', 'laugh', 'joke', 'haha', 'stupid', 'crazy', 'hilarious', 'idiot', 'comedian', 'fun', 'silly'],\n",
        "    'Drama': ['sad', 'cry', 'feelings', 'sorry', 'relationship', 'family', 'life', 'death', 'serious', 'story', 'love', 'lost', 'hope'],\n",
        "    'Sci-Fi': ['space', 'alien', 'robot', 'future', 'planet', 'ship', 'laser', 'time travel', 'science', 'galaxy', 'android', 'tech', 'technology', 'ai'],\n",
        "    'Horror': ['scared', 'fear', 'ghost', 'monster', 'scream', 'blood', 'die', 'haunted', 'terror', 'nightmare', 'killer', 'dark', 'evil'],\n",
        "    'Romance': ['love', 'kiss', 'heart', 'date', 'beautiful', 'together', 'forever', 'darling', 'marry', 'sweet', 'couple', 'wedding'],\n",
        "    'Thriller': ['suspense', 'danger', 'nervous', 'plot', 'secret', 'mystery', 'trap', 'risk', 'threat', 'tense', 'escape', 'spy', 'agent'],\n",
        "    'Fantasy': ['magic', 'wizard', 'dragon', 'sword', 'kingdom', 'elf', 'quest', 'myth', 'legend', 'creature', 'king', 'queen', 'prince', 'princess'],\n",
        "    'Animation': [],\n",
        "    'Documentary': ['real', 'story', 'life', 'world', 'people', 'history', 'fact', 'interview', 'evidence', 'nature', 'science']\n",
        "}\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d{1,2}:\\d{2}:\\d{2},\\d{3}\\s*-->\\s*\\d{1,2}:\\d{2}:\\d{2},\\d{3}', '', text)\n",
        "    text = re.sub(r'[\\[\\{\\(]\\s*\\d{1,2}:\\d{2}(:\\d{2})?\\s*[\\]\\}\\)]', '', text)\n",
        "    text = re.sub(r'<[/ BUI]?.*?>', '', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'^[\\s\\t]*[A-Z\\s]+:', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'[\\[\\{\\(][^\\]\\}\\)]*?:.*?[\\]\\}\\)]', '', text)\n",
        "    text = re.sub(r'[#*]', '', text)\n",
        "    text = re.sub(r'[-=]{2,}', ' ', text)\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def generate_overview_extractive(full_text, max_chars=MAX_OVERVIEW_CHARS):\n",
        "    if not full_text or not isinstance(full_text, str) or len(full_text.strip()) < 10:\n",
        "        return \"\"\n",
        "    try:\n",
        "        sentences = sent_tokenize(full_text)\n",
        "    except LookupError as e:\n",
        "        print(f\"\\n--- NLTK Tokenizer Warning (generate_overview_extractive) ---\")\n",
        "        print(f\"Sentence tokenization failed for an entry due to missing NLTK resource: {e}\")\n",
        "        print(\"This might happen if an NLTK download (e.g. 'punkt' or 'punkt_tab') is incomplete or corrupted.\")\n",
        "        print(\"Skipping summary generation for this entry.\")\n",
        "        print(\"Ensure all required NLTK data was downloaded at script start.\")\n",
        "        print(\"--------------------------------------------------------------\\n\")\n",
        "        return full_text[:max_chars].strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Sentence tokenization failed unexpectedly in generate_overview_extractive. Error: {e}. Skipping summary.\")\n",
        "        return full_text[:max_chars].strip()\n",
        "\n",
        "    if not sentences:\n",
        "        return \"\"\n",
        "    cleaned_full_text = preprocess_text(full_text)\n",
        "    if not cleaned_full_text:\n",
        "        return sentences[0][:max_chars] if sentences else \"\"\n",
        "    words = word_tokenize(cleaned_full_text)\n",
        "    word_frequencies = Counter(word for word in words if word not in STOP_WORDS and len(word) > 1)\n",
        "    if not word_frequencies:\n",
        "         return sentences[0][:max_chars] if sentences else \"\"\n",
        "    sentence_scores = {}\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        cleaned_sentence_words = word_tokenize(preprocess_text(sentence))\n",
        "        score = sum(word_frequencies[word] for word in cleaned_sentence_words if word in word_frequencies)\n",
        "        sentence_scores[i] = score\n",
        "    num_sentences_to_consider = min(len(sentences) // 2 + 1, 20)\n",
        "    k = min(num_sentences_to_consider, len(sentences))\n",
        "    if k <= 0: return \"\"\n",
        "    try:\n",
        "        if not sentence_scores:\n",
        "             top_sentence_indices = list(range(min(k, len(sentences))))\n",
        "        else:\n",
        "            top_sentence_indices = heapq.nlargest(k, sentence_scores, key=sentence_scores.get)\n",
        "            top_sentence_indices.sort()\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Error during sentence selection for summary: {e}. Using first sentences.\")\n",
        "        top_sentence_indices = list(range(min(k, len(sentences))))\n",
        "    summary = \"\"\n",
        "    current_length = 0\n",
        "    for index in top_sentence_indices:\n",
        "        if index < len(sentences):\n",
        "            sentence = sentences[index].strip()\n",
        "            if not sentence: continue\n",
        "            needed_length = len(sentence) + (1 if summary else 0)\n",
        "            if current_length + needed_length <= max_chars:\n",
        "                summary += (\" \" if summary else \"\") + sentence\n",
        "                current_length += needed_length\n",
        "            else:\n",
        "                if not summary:\n",
        "                    summary = sentence[:max_chars]\n",
        "                    current_length = len(summary)\n",
        "                break\n",
        "    if not summary and sentences:\n",
        "         summary = sentences[0][:max_chars].strip()\n",
        "    return summary.strip()[:max_chars]\n",
        "\n",
        "def extract_keywords_tfidf(full_text, num_keywords=NUM_KEYWORDS):\n",
        "    keywords = []\n",
        "    try:\n",
        "        if not full_text or not isinstance(full_text, str):\n",
        "            return []\n",
        "        processed_text = preprocess_text(full_text)\n",
        "        if not processed_text or len(processed_text.split()) < 5:\n",
        "             words = word_tokenize(processed_text)\n",
        "             word_counts = Counter(w for w in words if w not in STOP_WORDS and len(w) > 2)\n",
        "             keywords = [word for word, count in word_counts.most_common(num_keywords)]\n",
        "             return keywords\n",
        "        vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_features=2000, min_df=1)\n",
        "        tfidf_matrix = vectorizer.fit_transform([processed_text])\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "        scores = tfidf_matrix.toarray().flatten()\n",
        "        if len(feature_names) == 0:\n",
        "             words = word_tokenize(processed_text)\n",
        "             word_counts = Counter(w for w in words if w not in STOP_WORDS and len(w) > 2)\n",
        "             keywords = [word for word, count in word_counts.most_common(num_keywords)]\n",
        "             return keywords\n",
        "        actual_num_keywords = min(num_keywords, len(feature_names))\n",
        "        top_indices = scores.argsort()[-actual_num_keywords:][::-1]\n",
        "        keywords = [feature_names[i] for i in top_indices]\n",
        "        return keywords\n",
        "    except ValueError as e:\n",
        "        print(f\"Warning: TF-IDF keyword extraction failed. Error: {e}. Falling back to word count.\")\n",
        "        if 'processed_text' not in locals():\n",
        "             processed_text = preprocess_text(full_text) if isinstance(full_text, str) else \"\"\n",
        "        words = word_tokenize(processed_text) # This could also raise LookupError if punkt_tab is still an issue\n",
        "        word_counts = Counter(w for w in words if w not in STOP_WORDS and len(w) > 2)\n",
        "        keywords = [word for word, count in word_counts.most_common(num_keywords)]\n",
        "        return keywords\n",
        "    except LookupError as e: # Explicitly catch LookupError for tokenization here too\n",
        "        print(f\"\\n--- NLTK Tokenizer Warning (extract_keywords_tfidf) ---\")\n",
        "        print(f\"Word tokenization failed for an entry due to missing NLTK resource: {e}\")\n",
        "        print(\"This might happen if an NLTK download (e.g. 'punkt' or 'punkt_tab') is incomplete or corrupted.\")\n",
        "        print(\"Skipping keyword generation for this entry.\")\n",
        "        print(\"Ensure all required NLTK data was downloaded at script start.\")\n",
        "        print(\"------------------------------------------------------------\\n\")\n",
        "        return [] # Return empty list\n",
        "    except Exception as e:\n",
        "         print(f\"An unexpected error occurred during keyword extraction: {e}\")\n",
        "         return []\n",
        "\n",
        "def identify_genres_heuristic(full_text, threshold_multiplier=0.0005, min_keyword_matches=3):\n",
        "    try:\n",
        "        if not full_text or not isinstance(full_text, str):\n",
        "            return [\"Unknown\"]\n",
        "        processed_text = preprocess_text(full_text)\n",
        "        if not processed_text:\n",
        "            return [\"Unknown\"]\n",
        "        words = word_tokenize(processed_text) # This can also raise LookupError\n",
        "        total_words = len(words)\n",
        "        if total_words == 0:\n",
        "            return [\"Unknown\"]\n",
        "        word_counts = Counter(words)\n",
        "        genre_scores = {}\n",
        "        for genre, keywords_list in GENRE_KEYWORDS.items():\n",
        "            if not keywords_list: continue\n",
        "            score = 0\n",
        "            matches = 0\n",
        "            for keyword in keywords_list:\n",
        "                if ' ' in keyword:\n",
        "                    phrase_count = processed_text.count(keyword)\n",
        "                    if phrase_count > 0:\n",
        "                        score += phrase_count * 2\n",
        "                        matches += phrase_count\n",
        "                elif keyword in word_counts:\n",
        "                    count = word_counts[keyword]\n",
        "                    score += count\n",
        "                    matches += count\n",
        "            normalized_score = score / total_words if total_words > 0 else 0\n",
        "            passes_threshold = (matches >= min_keyword_matches and normalized_score > (len(keywords_list) * threshold_multiplier)) or \\\n",
        "                               (matches > 0 and matches < min_keyword_matches and normalized_score > 0)\n",
        "            if passes_threshold:\n",
        "                 genre_scores[genre] = normalized_score\n",
        "        if not genre_scores:\n",
        "            return [\"Unknown\"]\n",
        "        sorted_genres = sorted(genre_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "        num_genres_to_return = 0\n",
        "        if len(sorted_genres) >= 3 and sorted_genres[1][1] > sorted_genres[0][1] * 0.4:\n",
        "            num_genres_to_return = 3\n",
        "        elif len(sorted_genres) >= 2 and sorted_genres[1][1] > sorted_genres[0][1] * 0.5:\n",
        "            num_genres_to_return = 2\n",
        "        elif len(sorted_genres) >= 1:\n",
        "            num_genres_to_return = 1\n",
        "        else:\n",
        "            return [\"Unknown\"]\n",
        "        num_genres_to_return = min(num_genres_to_return, len(sorted_genres))\n",
        "        matched_genres = [genre for genre, score in sorted_genres[:num_genres_to_return]]\n",
        "        return matched_genres if matched_genres else [\"Unknown\"]\n",
        "    except LookupError as e: # Explicitly catch LookupError for tokenization here too\n",
        "        print(f\"\\n--- NLTK Tokenizer Warning (identify_genres_heuristic) ---\")\n",
        "        print(f\"Word tokenization failed for an entry due to missing NLTK resource: {e}\")\n",
        "        print(\"This might happen if an NLTK download (e.g. 'punkt' or 'punkt_tab') is incomplete or corrupted.\")\n",
        "        print(\"Skipping genre identification for this entry.\")\n",
        "        print(\"Ensure all required NLTK data was downloaded at script start.\")\n",
        "        print(\"--------------------------------------------------------------\\n\")\n",
        "        return [\"Unknown\"]\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during genre identification: {e}\")\n",
        "        return [\"Unknown\"]\n",
        "\n",
        "# --- Main Processing Function ---\n",
        "# ... (your process_subtitle_file function remains the same) ...\n",
        "def process_subtitle_file(input_path, output_path, id_col, text_col):\n",
        "    print(f\"Reading CSV file: {input_path}...\")\n",
        "    try:\n",
        "        df = pd.read_csv(input_path, on_bad_lines='warn', engine='python')\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file not found at {input_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CSV: {e}\")\n",
        "        try:\n",
        "            print(\"Attempting to read CSV with latin-1 encoding...\")\n",
        "            df = pd.read_csv(input_path, on_bad_lines='warn', encoding='latin-1', engine='python')\n",
        "        except Exception as e2:\n",
        "            print(f\"Error reading CSV with latin-1 encoding as well: {e2}\")\n",
        "            return None\n",
        "\n",
        "    if id_col not in df.columns or text_col not in df.columns:\n",
        "        print(f\"Error: Missing required columns '{id_col}' or '{text_col}' in the CSV.\")\n",
        "        print(f\"Available columns: {df.columns.tolist()}\")\n",
        "        return None\n",
        "    print(f\"Initial rows loaded: {len(df)}\")\n",
        "    df.dropna(subset=[id_col, text_col], inplace=True)\n",
        "    print(f\"Rows after dropping NA in key columns: {len(df)}\")\n",
        "    df[text_col] = df[text_col].apply(lambda x: str(x) if pd.notnull(x) else '')\n",
        "    print(f\"Combining subtitles for each '{id_col}'...\")\n",
        "    try:\n",
        "        combined_df = df.groupby(id_col)[text_col].agg(' '.join).reset_index()\n",
        "        combined_df.rename(columns={text_col: 'full_subtitles'}, inplace=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during grouping and combining subtitles: {e}\")\n",
        "        return None\n",
        "    print(f\"Found {len(combined_df)} unique movies.\")\n",
        "    if len(combined_df) == 0:\n",
        "        print(\"No movie data found after grouping. Check your ID column and data.\")\n",
        "        return None\n",
        "    print(\"Analyzing subtitles (this may take a while)...\")\n",
        "    results = []\n",
        "    try:\n",
        "        from tqdm.auto import tqdm\n",
        "        iterator = tqdm(combined_df.iterrows(), total=len(combined_df), desc=\"Analyzing Movies\")\n",
        "    except ImportError:\n",
        "        print(\"Optional dependency 'tqdm' not found. Progress bar disabled. Install with: pip install tqdm\")\n",
        "        iterator = combined_df.iterrows()\n",
        "        progress_interval = max(1, len(combined_df) // 20)\n",
        "        processed_count = 0\n",
        "    for index, row in iterator:\n",
        "        movie_id = row[id_col]\n",
        "        full_text = row['full_subtitles']\n",
        "        try:\n",
        "             overview = generate_overview_extractive(full_text, MAX_OVERVIEW_CHARS)\n",
        "             keywords = extract_keywords_tfidf(full_text, NUM_KEYWORDS)\n",
        "             genres = identify_genres_heuristic(full_text)\n",
        "        except Exception as e: # General catch-all per movie, though specific catches are now in functions\n",
        "             print(f\"\\n--- ERROR processing movie ID: {movie_id} ---\")\n",
        "             print(f\"An unexpected error occurred: {e}\")\n",
        "             print(\"Skipping analysis for this movie.\")\n",
        "             print(\"----------------------------------------------\\n\")\n",
        "             overview = \"Analysis Error\"\n",
        "             keywords = []\n",
        "             genres = [\"Error\"]\n",
        "        results.append({\n",
        "            MOVIE_ID_COLUMN: movie_id,\n",
        "            'overview': overview,\n",
        "            'keywords': ', '.join(keywords),\n",
        "            'genres': ', '.join(genres),\n",
        "        })\n",
        "        if 'tqdm' not in sys.modules:\n",
        "            processed_count += 1\n",
        "            if processed_count % progress_interval == 0 or processed_count == len(combined_df):\n",
        "                 print(f\"  Processed {processed_count}/{len(combined_df)} movies...\")\n",
        "    print(\"Analysis complete.\")\n",
        "    if not results:\n",
        "        print(\"Warning: No results were generated from the analysis.\")\n",
        "        return None\n",
        "    output_df = pd.DataFrame(results)\n",
        "    try:\n",
        "        output_df.to_csv(output_path, index=False, encoding='utf-8')\n",
        "        print(f\"Results saved to: {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving results to CSV: {e}\")\n",
        "    return output_df\n",
        "\n",
        "# --- Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    processed_data = process_subtitle_file(\n",
        "        INPUT_CSV_FILE,\n",
        "        OUTPUT_CSV_FILE,\n",
        "        MOVIE_ID_COLUMN,\n",
        "        SUBTITLE_TEXT_COLUMN\n",
        "    )\n",
        "    if processed_data is not None:\n",
        "        print(\"\\n--- Sample Output (First 5 rows) ---\")\n",
        "        with pd.option_context('display.max_colwidth', 100):\n",
        "             print(processed_data.head())\n",
        "        print(\"\\n-------------------------------------\")\n",
        "    else:\n",
        "        print(\"Processing failed or produced no results.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks1IZuTD-S2v",
        "outputId": "6583746a-1bae-4f6b-d4db-57558edbedca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Starting CSV Merge Script ---\n",
            "Attempting to load metadata file: movies_meta.csv\n",
            "  Successfully loaded metadata: 4690 rows, 24 columns.\n",
            "Attempting to load analysis file: movie_analysis_output.csv\n",
            "  Successfully loaded analysis results: 3124 rows, 4 columns.\n",
            "\n",
            "Merging the two dataframes on column: 'imdb_id'...\n",
            "Merge complete. Resulting dataframe has 3128 rows and 27 columns.\n",
            "\n",
            "Successfully saved merged data to: merged_movie_data.csv\n",
            "\n",
            "--- Merge Script Finished ---\n",
            "Showing first 5 rows of the merged data:\n",
            "   adult  \\\n",
            "0  False   \n",
            "1  False   \n",
            "2  False   \n",
            "3  False   \n",
            "4  False   \n",
            "\n",
            "                                                             belongs_to_collection  \\\n",
            "0  {'id': 10194, 'name': 'Toy Story Collection', 'poster_path': '/7G9915LfUQ2lV...   \n",
            "1                                                                              NaN   \n",
            "2  {'id': 645, 'name': 'James Bond Collection', 'poster_path': '/HORpg5CSkmeQlA...   \n",
            "3                                                                              NaN   \n",
            "4                                                                              NaN   \n",
            "\n",
            "     budget  \\\n",
            "0  30000000   \n",
            "1  65000000   \n",
            "2  58000000   \n",
            "3   3600000   \n",
            "4  29500000   \n",
            "\n",
            "                                                                          genres_x  \\\n",
            "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751...   \n",
            "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, 'name': 'Fantasy'}, {'id': 1075...   \n",
            "2  [{'id': 12, 'name': 'Adventure'}, {'id': 28, 'name': 'Action'}, {'id': 53, '...   \n",
            "3                  [{'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}]   \n",
            "4  [{'id': 878, 'name': 'Science Fiction'}, {'id': 53, 'name': 'Thriller'}, {'i...   \n",
            "\n",
            "                                                homepage    id    imdb_id  \\\n",
            "0                   http://toystory.disney.com/toy-story   862  tt0114709   \n",
            "1                                                    NaN  8844  tt0113497   \n",
            "2           http://www.mgm.com/view/movie/757/Goldeneye/   710  tt0113189   \n",
            "3  http://www.mgm.com/title_title.do?title_star=LEAVINGL   451  tt0113627   \n",
            "4                                                    NaN    63  tt0114746   \n",
            "\n",
            "  original_language     original_title  \\\n",
            "0                en          Toy Story   \n",
            "1                en            Jumanji   \n",
            "2                en          GoldenEye   \n",
            "3                en  Leaving Las Vegas   \n",
            "4                en     Twelve Monkeys   \n",
            "\n",
            "                                                                        overview_x  \\\n",
            "0  Led by Woody, Andy's toys live happily in his room until Andy's birthday bri...   \n",
            "1  When siblings Judy and Peter discover an enchanted board game that opens the...   \n",
            "2  James Bond must unmask the mysterious head of the Janus Syndicate and preven...   \n",
            "3  Ben Sanderson, an alcoholic Hollywood screenwriter who lost everything becau...   \n",
            "4  In the year 2035, convict James Cole reluctantly volunteers to be sent back ...   \n",
            "\n",
            "   popularity                       poster_path  \\\n",
            "0   21.946943  /rhIRbceoE9lR4veEXuwCC2wARtG.jpg   \n",
            "1   17.015539  /vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg   \n",
            "2   14.686036  /5c0ovjT41KnYIHYuF4AWsTe3sKh.jpg   \n",
            "3   10.332025  /37qHRJxnSh5YkuaN9FgfNnMl3Tj.jpg   \n",
            "4   12.297305  /6Sj9wDu3YugthXsU0Vry5XFAZGg.jpg   \n",
            "\n",
            "                                                              production_companies  \\\n",
            "0                                   [{'name': 'Pixar Animation Studios', 'id': 3}]   \n",
            "1  [{'name': 'TriStar Pictures', 'id': 559}, {'name': 'Teitler Film', 'id': 255...   \n",
            "2  [{'name': 'United Artists', 'id': 60}, {'name': 'Eon Productions', 'id': 7576}]   \n",
            "3  [{'name': 'United Artists', 'id': 60}, {'name': 'Intial Productions', 'id': ...   \n",
            "4  [{'name': 'Universal Pictures', 'id': 33}, {'name': 'Atlas Entertainment', '...   \n",
            "\n",
            "                                                              production_countries  \\\n",
            "0                       [{'iso_3166_1': 'US', 'name': 'United States of America'}]   \n",
            "1                       [{'iso_3166_1': 'US', 'name': 'United States of America'}]   \n",
            "2  [{'iso_3166_1': 'GB', 'name': 'United Kingdom'}, {'iso_3166_1': 'US', 'name'...   \n",
            "3                       [{'iso_3166_1': 'US', 'name': 'United States of America'}]   \n",
            "4                       [{'iso_3166_1': 'US', 'name': 'United States of America'}]   \n",
            "\n",
            "  release_date      revenue  runtime  \\\n",
            "0   1995-10-30  373554033.0     81.0   \n",
            "1   1995-12-15  262797249.0    104.0   \n",
            "2   1995-11-16  352194034.0    130.0   \n",
            "3   1995-10-27   49800000.0    112.0   \n",
            "4   1995-12-29  168840000.0    129.0   \n",
            "\n",
            "                                                                  spoken_languages  \\\n",
            "0                                         [{'iso_639_1': 'en', 'name': 'English'}]   \n",
            "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso_639_1': 'fr', 'name': 'Frana...   \n",
            "2  [{'iso_639_1': 'en', 'name': 'English'}, {'iso_639_1': 'ru', 'name': 'P...   \n",
            "3                                         [{'iso_639_1': 'en', 'name': 'English'}]   \n",
            "4  [{'iso_639_1': 'en', 'name': 'English'}, {'iso_639_1': 'fr', 'name': 'Frana...   \n",
            "\n",
            "     status                                    tagline              title  \\\n",
            "0  Released                                        NaN          Toy Story   \n",
            "1  Released  Roll the dice and unleash the excitement!            Jumanji   \n",
            "2  Released       No limits. No fears. No substitutes.          GoldenEye   \n",
            "3  Released             I Love You... The Way You Are.  Leaving Las Vegas   \n",
            "4  Released                     The future is history.     Twelve Monkeys   \n",
            "\n",
            "   video  vote_average  vote_count  \\\n",
            "0  False           7.7      5415.0   \n",
            "1  False           6.9      2413.0   \n",
            "2  False           6.6      1194.0   \n",
            "3  False           7.1       365.0   \n",
            "4  False           7.4      2470.0   \n",
            "\n",
            "                                                                        overview_y  \\\n",
            "0  BOY: All right, everyone!\\nThis... is a stick-up! Don't anybody move! Now, e...   \n",
            "1  Hey, kiddo. - What?\\n- I found something. You gotta check this out. \"Jumanji...   \n",
            "2  <u><b>CAPTIONING BY KOUSHIK DAS</b></u> BEG YOUR PARDON. FORGOT TO KNOCK. <i...   \n",
            "3  - To a wonderful film. You were great.\\n- Thank you. - What a romantic you a...   \n",
            "4  /Flight 784 for San Francisco\\n/is now ready for boarding. /Passengers for f...   \n",
            "\n",
            "                                                         keywords genres_y  \n",
            "0         buzz, oh, woody, hey, come, got, right, dont, im, youre  Unknown  \n",
            "1        like, oh, im, dont, okay, yeah, youre, think, just, know  Unknown  \n",
            "2  james, know, yes, good, im, bond, dont, just, goldeneye, boris  Unknown  \n",
            "3     im, just, dont, want, know, youre, right, ill, really, like  Unknown  \n",
            "4      dont, know, im, youre, just, right, want, james, got, cole  Unknown  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "# --- Configuration ---\n",
        "METADATA_FILE = 'movies_meta.csv'\n",
        "ANALYSIS_FILE = 'movie_analysis_output.csv'\n",
        "OUTPUT_FILE = 'merged_movie_data.csv'\n",
        "MERGE_COLUMN = 'imdb_id' # The common column to join on\n",
        "\n",
        "# --- Main Merge Function ---\n",
        "def merge_csv_files(meta_path, analysis_path, output_path, merge_col):\n",
        "    \"\"\"\n",
        "    Loads two CSV files, merges them based on a specified column,\n",
        "    and saves the result to a new CSV file.\n",
        "    \"\"\"\n",
        "    print(f\"Attempting to load metadata file: {meta_path}\")\n",
        "    try:\n",
        "        # Read metadata, treat merge column as string to avoid type issues\n",
        "        df_meta = pd.read_csv(meta_path, dtype={merge_col: str})\n",
        "        print(f\"  Successfully loaded metadata: {len(df_meta)} rows, {len(df_meta.columns)} columns.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Metadata file not found at '{meta_path}'\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading metadata file '{meta_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Attempting to load analysis file: {analysis_path}\")\n",
        "    try:\n",
        "         # Read analysis results, treat merge column as string\n",
        "        df_analysis = pd.read_csv(analysis_path, dtype={merge_col: str})\n",
        "        print(f\"  Successfully loaded analysis results: {len(df_analysis)} rows, {len(df_analysis.columns)} columns.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Analysis file not found at '{analysis_path}'\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading analysis file '{analysis_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "    # --- Validate Merge Column ---\n",
        "    if merge_col not in df_meta.columns:\n",
        "        print(f\"Error: Merge column '{merge_col}' not found in metadata file '{meta_path}'.\")\n",
        "        print(f\"Available columns: {df_meta.columns.tolist()}\")\n",
        "        return None\n",
        "    if merge_col not in df_analysis.columns:\n",
        "        print(f\"Error: Merge column '{merge_col}' not found in analysis file '{analysis_path}'.\")\n",
        "        print(f\"Available columns: {df_analysis.columns.tolist()}\")\n",
        "        return None\n",
        "\n",
        "    # --- Perform the Merge ---\n",
        "    print(f\"\\nMerging the two dataframes on column: '{merge_col}'...\")\n",
        "\n",
        "    # Use 'inner' merge to keep only rows where imdb_id exists in BOTH files.\n",
        "    # Other options:\n",
        "    # 'left': Keep all rows from df_meta, add analysis data where matched, NaN otherwise.\n",
        "    # 'right': Keep all rows from df_analysis, add meta data where matched, NaN otherwise.\n",
        "    # 'outer': Keep all rows from both, fill missing data with NaN.\n",
        "    merged_df = pd.merge(\n",
        "        left=df_meta,\n",
        "        right=df_analysis,\n",
        "        on=merge_col,\n",
        "        how='inner' # Choose 'inner', 'left', 'right', or 'outer'\n",
        "    )\n",
        "\n",
        "    print(f\"Merge complete. Resulting dataframe has {len(merged_df)} rows and {len(merged_df.columns)} columns.\")\n",
        "\n",
        "    if len(merged_df) == 0:\n",
        "        print(\"Warning: The merged dataframe is empty. This means no common\")\n",
        "        print(f\"'{merge_col}' values were found between the two files using an 'inner' merge.\")\n",
        "        print(f\"Consider using 'how='left'' or 'how='outer'' if you expect unmatched rows.\")\n",
        "        # Optionally return None or the empty df depending on desired behavior\n",
        "        # return None\n",
        "        return merged_df\n",
        "\n",
        "\n",
        "    # --- Save the Result ---\n",
        "    try:\n",
        "        merged_df.to_csv(output_path, index=False, encoding='utf-8')\n",
        "        print(f\"\\nSuccessfully saved merged data to: {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving merged file to '{output_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "# --- Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Starting CSV Merge Script ---\")\n",
        "    final_df = merge_csv_files(\n",
        "        METADATA_FILE,\n",
        "        ANALYSIS_FILE,\n",
        "        OUTPUT_FILE,\n",
        "        MERGE_COLUMN\n",
        "    )\n",
        "\n",
        "    if final_df is not None:\n",
        "        print(\"\\n--- Merge Script Finished ---\")\n",
        "        print(\"Showing first 5 rows of the merged data:\")\n",
        "        # Display more content if overview/keywords are long\n",
        "        with pd.option_context('display.max_colwidth', 80, 'display.max_columns', None):\n",
        "            print(final_df.head())\n",
        "    else:\n",
        "        print(\"\\n--- Merge Script Failed ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DIYQF2dFzjs",
        "outputId": "e892b93b-6c02-4fc7-8193-ec69a55a248d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Counting unique values in column 'homepage' ---\n",
            "Attempting to load file: merged_movie_data.csv\n",
            "  Successfully loaded file: 3128 rows, 27 columns.\n",
            "\n",
            "Analysis complete for column: 'homepage'\n",
            "Number of unique non-null values: 664\n",
            "\n",
            "--- Script Finished ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "# --- Configuration ---\n",
        "INPUT_FILE = 'merged_movie_data.csv' # The merged CSV file\n",
        "COLUMN_TO_COUNT = 'homepage'        # The column containing homepage URLs\n",
        "\n",
        "# --- Function to count unique values ---\n",
        "def count_unique_in_column(filepath, column_name):\n",
        "    \"\"\"\n",
        "    Loads a CSV file and counts the number of unique non-null values\n",
        "    in a specified column.\n",
        "    \"\"\"\n",
        "    print(f\"Attempting to load file: {filepath}\")\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        print(f\"  Successfully loaded file: {len(df)} rows, {len(df.columns)} columns.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at '{filepath}'\")\n",
        "        return None # Indicate failure\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading file '{filepath}': {e}\")\n",
        "        return None # Indicate failure\n",
        "\n",
        "    # --- Validate Column ---\n",
        "    if column_name not in df.columns:\n",
        "        print(f\"Error: Column '{column_name}' not found in the file.\")\n",
        "        print(f\"Available columns are: {df.columns.tolist()}\")\n",
        "        return None # Indicate failure\n",
        "\n",
        "    # --- Count Unique Values ---\n",
        "    # .nunique() efficiently counts distinct non-null values\n",
        "    unique_count = df[column_name].nunique()\n",
        "\n",
        "    print(f\"\\nAnalysis complete for column: '{column_name}'\")\n",
        "    print(f\"Number of unique non-null values: {unique_count}\")\n",
        "\n",
        "    # --- Optional: Show some unique values (if needed) ---\n",
        "    # If you want to see *what* some of the unique values are:\n",
        "    # try:\n",
        "    #     unique_values_sample = df[column_name].dropna().unique()\n",
        "    #     print(f\"\\nSample of unique values (up to 10):\")\n",
        "    #     print(unique_values_sample[:10])\n",
        "    # except Exception as e:\n",
        "    #     print(f\"Could not display unique values sample due to error: {e}\")\n",
        "\n",
        "    return unique_count\n",
        "\n",
        "# --- Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"--- Counting unique values in column '{COLUMN_TO_COUNT}' ---\")\n",
        "    result = count_unique_in_column(INPUT_FILE, COLUMN_TO_COUNT)\n",
        "\n",
        "    if result is not None:\n",
        "        print(\"\\n--- Script Finished ---\")\n",
        "    else:\n",
        "        print(\"\\n--- Script Failed or Column Not Found ---\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03a6d7c2ad6f4259a5221bbf9a16ac63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee0a143677c4005ac937e10b0cb01a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "111e5fab51d4436fb086fe1a22592a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc4cabf4767848feb3bf3bc6c604c003",
              "IPY_MODEL_68245612e87747bfba3bb04a40ed2fa2",
              "IPY_MODEL_dc7eb433c22c4d0faf1a4720ded66ea0"
            ],
            "layout": "IPY_MODEL_2ad845f73097439c97c93972e1873ebc"
          }
        },
        "1141c1dd9fe84a6babcf11a6792ae3b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ad845f73097439c97c93972e1873ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ce8724a0a0545178d53a2105f3dcb99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1141c1dd9fe84a6babcf11a6792ae3b6",
            "max": 4665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7000e58e578e4ad8ae5f3782e6f13ace",
            "value": 69
          }
        },
        "336da3f20b4b4a9fb210f785da66e9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb0d0cbeb0747349a92b765c55dd3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c748f7f0ebf34699b824cd65646579b4",
            "placeholder": "",
            "style": "IPY_MODEL_c4130824a7254f4b9a45d6cd2c93a3d4",
            "value": "AnalyzingMovies:1%"
          }
        },
        "58c55a3be4414da1bb2041f49c005ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68245612e87747bfba3bb04a40ed2fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_336da3f20b4b4a9fb210f785da66e9f3",
            "max": 3124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58c55a3be4414da1bb2041f49c005ed3",
            "value": 3124
          }
        },
        "7000e58e578e4ad8ae5f3782e6f13ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7572d489433b482b9190f44edf26caa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bbd6065a1ac4d43a1a11e2d3856a4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cb0d0cbeb0747349a92b765c55dd3ac",
              "IPY_MODEL_2ce8724a0a0545178d53a2105f3dcb99",
              "IPY_MODEL_c4f6861260fd4fceba61f0c6d45a433f"
            ],
            "layout": "IPY_MODEL_988f2f840b9c4b9883e2a98a949518ec"
          }
        },
        "8f189425d1fd49838895ffc48da8276c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "988f2f840b9c4b9883e2a98a949518ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b12ae2543c1344cd8ac3eeef22be443b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbabb58bd65446a4a204820b842b06cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4130824a7254f4b9a45d6cd2c93a3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4f6861260fd4fceba61f0c6d45a433f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbabb58bd65446a4a204820b842b06cf",
            "placeholder": "",
            "style": "IPY_MODEL_0ee0a143677c4005ac937e10b0cb01a5",
            "value": "69/4665[00:29&lt;42:37,1.80it/s]"
          }
        },
        "c748f7f0ebf34699b824cd65646579b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc4cabf4767848feb3bf3bc6c604c003": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7572d489433b482b9190f44edf26caa4",
            "placeholder": "",
            "style": "IPY_MODEL_b12ae2543c1344cd8ac3eeef22be443b",
            "value": "AnalyzingMovies:100%"
          }
        },
        "dc7eb433c22c4d0faf1a4720ded66ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03a6d7c2ad6f4259a5221bbf9a16ac63",
            "placeholder": "",
            "style": "IPY_MODEL_8f189425d1fd49838895ffc48da8276c",
            "value": "3124/3124[03:17&lt;00:00,20.58it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}