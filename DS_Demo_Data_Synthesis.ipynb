{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p_e_8CrOd98",
        "outputId": "9e2a5790-1a3d-47e4-d86f-e58dc94c7ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KF8f5KiOHXe",
        "outputId": "df2c57b3-d0e4-4837-c15e-2b5736833cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Checking and Downloading NLTK Resources ---\n",
            "NLTK resource 'punkt' (path: 'tokenizers/punkt') already found.\n",
            "NLTK resource 'stopwords' (path: 'corpora/stopwords') already found.\n",
            "NLTK resource 'punkt_tab' (path: 'tokenizers/punkt_tab') already found.\n",
            "--- All necessary NLTK resources seem to be available. ---\n",
            "\n",
            "Please paste or type your paragraph below. When finished, press Enter.\n",
            "If pasting multiple lines, Colab's input() will handle it as one line break.\n",
            "To submit, just press Enter after your text.\n",
            "Enter your paragraph: The Spark SQL Engine is a core component that drives DataFrames and DataSets, with an emphasis on being SQL-first. It is responsible for connecting to the Apache Hive metastore to manage tables and for reading and writing data using various formats, converting them into tables. Spark SQL also provides a bridge to SQL data via JDBC/ODBC. Crucially, it generates optimized query plans and compact bytecode.\n",
            "\n",
            "--- Processing ---\n",
            "\n",
            "--- Overview ---\n",
            "The Spark SQL Engine is a core component that drives DataFrames and DataSets, with an emphasis on being SQL-first. It is responsible for connecting to the Apache Hive metastore to manage tables and for reading and writing data using various formats, converting them into tables. Spark SQL also provides a bridge to SQL data via JDBC/ODBC.\n",
            "\n",
            "--- Keywords ---\n",
            "sql, spark, tables, data, engine, core, component\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import heapq\n",
        "import string\n",
        "from collections import Counter\n",
        "import os # For checking paths if needed\n",
        "\n",
        "# --- Robust NLTK Resource Download and Verification ---\n",
        "def download_and_verify_nltk_resources():\n",
        "    resources_to_check = {\n",
        "        'punkt': 'tokenizers/punkt',\n",
        "        'stopwords': 'corpora/stopwords',\n",
        "        'punkt_tab': 'tokenizers/punkt_tab'  # Added this line based on the new error\n",
        "    }\n",
        "    all_verified = True\n",
        "\n",
        "    print(\"--- Checking and Downloading NLTK Resources ---\")\n",
        "    # Ensure the default NLTK data path is in the search list (usually /root/nltk_data in Colab)\n",
        "    # default_nltk_path = os.path.join(os.path.expanduser(\"~\"), \"nltk_data\")\n",
        "    # if default_nltk_path not in nltk.data.path:\n",
        "    #     nltk.data.path.append(default_nltk_path)\n",
        "\n",
        "\n",
        "    for resource_name, resource_path_suffix in resources_to_check.items():\n",
        "        try:\n",
        "            nltk.data.find(resource_path_suffix)\n",
        "            print(f\"NLTK resource '{resource_name}' (path: '{resource_path_suffix}') already found.\")\n",
        "        except LookupError:\n",
        "            print(f\"NLTK resource '{resource_name}' (path: '{resource_path_suffix}') not found. Attempting download...\")\n",
        "            try:\n",
        "                # Make download verbose to see any issues\n",
        "                # nltk.download() returns True on success, False or raises an exception on failure.\n",
        "                if nltk.download(resource_name, quiet=False): # quiet=False for more output\n",
        "                    print(f\"nltk.download('{resource_name}') reported completion.\")\n",
        "                    # VERIFY IMMEDIATELY\n",
        "                    try:\n",
        "                        nltk.data.find(resource_path_suffix)\n",
        "                        print(f\"SUCCESS: '{resource_name}' downloaded and verified by nltk.data.find().\")\n",
        "                    except LookupError:\n",
        "                        print(f\"CRITICAL ERROR: '{resource_name}' download reported completion, BUT nltk.data.find() STILL CANNOT LOCATE IT.\")\n",
        "                        print(f\"NLTK is searching for '{resource_path_suffix}' in these paths: {nltk.data.path}\")\n",
        "                        print(\"This can happen if download was incomplete or NLTK's path list is not updated.\")\n",
        "                        all_verified = False\n",
        "                else:\n",
        "                    print(f\"nltk.download('{resource_name}') returned False or failed. Resource may not be available.\")\n",
        "                    all_verified = False\n",
        "            except Exception as e:\n",
        "                print(f\"An exception occurred during download or verification of '{resource_name}': {e}\")\n",
        "                all_verified = False\n",
        "\n",
        "    if all_verified:\n",
        "        print(\"--- All necessary NLTK resources seem to be available. ---\")\n",
        "    else:\n",
        "        print(\"--- CRITICAL FAILURE: One or more NLTK resources could not be made available. ---\")\n",
        "        print(\"The script cannot proceed reliably.\")\n",
        "        print(\"Recommendations:\")\n",
        "        print(\"1. Runtime > Restart Runtime. Then run this cell again.\")\n",
        "        print(\"2. Check your internet connection.\")\n",
        "        print(f\"NLTK's current data search paths: {nltk.data.path}\")\n",
        "    return all_verified\n",
        "\n",
        "# --- Call the download and verification function at the start ---\n",
        "NLTK_RESOURCES_READY = download_and_verify_nltk_resources()\n",
        "\n",
        "\n",
        "# --- Functions --- (Only define them; they will be called if NLTK_RESOURCES_READY)\n",
        "\n",
        "def get_paragraph_colab():\n",
        "    \"\"\"Prompts the user to enter a paragraph in a Colab environment.\"\"\"\n",
        "    print(\"\\nPlease paste or type your paragraph below. When finished, press Enter.\")\n",
        "    print(\"If pasting multiple lines, Colab's input() will handle it as one line break.\")\n",
        "    print(\"To submit, just press Enter after your text.\")\n",
        "    paragraph = input(\"Enter your paragraph: \")\n",
        "    return paragraph\n",
        "\n",
        "def generate_overview(text, num_sentences=3):\n",
        "    \"\"\"Generates a simple extractive summary.\"\"\"\n",
        "    if not NLTK_RESOURCES_READY:\n",
        "        return \"NLTK resources not ready. Cannot generate overview.\"\n",
        "    if not text or len(text.split()) < 10:\n",
        "         return \"Input text is too short for a meaningful overview.\"\n",
        "\n",
        "    sentences = nltk.sent_tokenize(text) # Relies on 'punkt' (and its dependencies like 'punkt_tab')\n",
        "    if len(sentences) <= num_sentences:\n",
        "        return text\n",
        "\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english') + list(string.punctuation)) # Relies on 'stopwords'\n",
        "    words = [word.lower() for word in nltk.word_tokenize(text) if word.lower() not in stop_words and word.isalnum()] # Relies on 'punkt' (and its dependencies)\n",
        "\n",
        "    if not words:\n",
        "        return \"No content words found after removing stop words and punctuation.\"\n",
        "\n",
        "    word_freq = Counter(words)\n",
        "    sentence_scores = {}\n",
        "    for sentence in sentences:\n",
        "        sentence_words = [word.lower() for word in nltk.word_tokenize(sentence) if word.lower() not in stop_words and word.isalnum()]\n",
        "        score = sum(word_freq[word] for word in sentence_words)\n",
        "        if len(sentence_words) > 0:\n",
        "             sentence_scores[sentence] = score / len(sentence_words)\n",
        "        else:\n",
        "             sentence_scores[sentence] = 0\n",
        "\n",
        "    summary_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
        "    overview = \" \".join(sorted(summary_sentences, key=lambda s: sentences.index(s)))\n",
        "    return overview\n",
        "\n",
        "def extract_keywords(text, num_keywords=5):\n",
        "    \"\"\"Extracts the most frequent non-stop words as keywords.\"\"\"\n",
        "    if not NLTK_RESOURCES_READY:\n",
        "        return []\n",
        "    if not text:\n",
        "        return []\n",
        "\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english') + list(string.punctuation)) # Relies on 'stopwords'\n",
        "    words = [word.lower() for word in nltk.word_tokenize(text) if word.lower() not in stop_words and word.isalnum()] # Relies on 'punkt' (and its dependencies)\n",
        "\n",
        "    if not words:\n",
        "        return []\n",
        "\n",
        "    word_freq = Counter(words)\n",
        "    keywords = [word for word, freq in word_freq.most_common(num_keywords)]\n",
        "    return keywords\n",
        "\n",
        "# --- Main Execution ---\n",
        "if NLTK_RESOURCES_READY:\n",
        "    paragraph = get_paragraph_colab()\n",
        "\n",
        "    if not paragraph:\n",
        "        print(\"\\nNo input received. Exiting.\")\n",
        "    else:\n",
        "        print(\"\\n--- Processing ---\")\n",
        "        try:\n",
        "            overview_text = generate_overview(paragraph, num_sentences=3)\n",
        "            keyword_list = extract_keywords(paragraph, num_keywords=7)\n",
        "\n",
        "            print(\"\\n--- Overview ---\")\n",
        "            print(overview_text)\n",
        "\n",
        "            print(\"\\n--- Keywords ---\")\n",
        "            if keyword_list:\n",
        "                print(\", \".join(keyword_list))\n",
        "            else:\n",
        "                print(\"Could not extract keywords (perhaps the text was too short or only contained stop words).\")\n",
        "\n",
        "        except LookupError as le:\n",
        "            print(f\"\\nUNEXPECTED NLTK LOOKUP ERROR DURING PROCESSING: {le}\")\n",
        "            print(\"This indicates a required NLTK resource was still not found, despite earlier checks.\")\n",
        "            print(\"This is highly unusual if the initial checks passed and all listed resources were verified.\")\n",
        "            print(f\"NLTK search paths for data: {nltk.data.path}\")\n",
        "            print(\"Please try restarting the Colab Runtime (Runtime > Restart Runtime) and run the cell again.\")\n",
        "            print(\"If the error persists for a specific resource (e.g., 'punkt_tab'), ensure it was listed in 'resources_to_check' at the top of the script.\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nAN UNEXPECTED ERROR OCCURRED DURING PROCESSING: {e}\")\n",
        "else:\n",
        "    print(\"\\nScript cannot proceed because NLTK resources were not properly downloaded or verified.\")\n",
        "    print(\"Please review the download messages above.\")\n",
        "    print(\"Try: 1. Check internet. 2. Runtime > Restart Runtime. 3. Run the cell again.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XvB-D124O22j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}